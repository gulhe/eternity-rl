@document.meta
title: todo
authors: pierrotlc
categories: notes
created: 2023-03-08
updated: 2023-03-18
@end

* TODO
  - (x) A batched environment, based on tensor operations.
  -- (x) Batch matches.
  -- (x) Reset (tests).
  -- (x) Batch actions.
  --- (x) Batched rolls.
  --- (x) Batched swap.
  - (x) Reinforce using the batched environment.
  -- (x) sample actions.
  -- (x) rollout.
  -- (x) metrics.
  -- (x) devices.
  - (x) Compute cumulated returns with decay factor (pytorch implementation).
  -- (x) {https://discuss.pytorch.org/t/cumulative-sum-with-decay-factor/69788/2}[idea].
  -- (x) Add the mask in the computations.
  -- (x) Include the gamma factor in the loss computation?
  --- (x) https://ai.stackexchange.com/questions/7680/why-does-the-discount-rate-in-the-reinforce-algorithm-appear-twice
  -- (x) UnitTest.
  - ( ) Add a value network as a baseline.
  -- ( ) Add timesteps for value computations.
  - ( ) Explore the importance of the multiple HPs.
  -- ( ) Model size.
  -- ( ) Learning rate, optimizer, betas...
  -- ( ) Gamma factor.
  -- ( ) Number of max steps.
  -- ( ) Reward type.
  - ( ) A cleaner version of the MCTS.
  - ( ) Mixing MCTS with neural networks -> AlphaZero.
